---
title: "[도서 정리]통계 101 x 데이터 분석"
excerpt: "7장. 상관과 회귀"
classes: wide

categories:
  - Notes
---
# 통계 101 x 데이터 분석
## 7장. 상관과 회귀

양적 변수 사이의 관계를 밝히는 "상관"과 "회귀".  
- 상관 : 상관계수를 이용하여 두 변수 간의 관계의 강도를 평가.
- 회귀 : 어떤 변수 X와 다른 변수 Y 사이의 관계를 밝히고, 관계성을 모형화.

<br/>

### 양적 변수 사이의 관계
#### 산점도
두 종류의 양적 변수 데이터를 얻었다면 한 변수를 X축, 다른 변수를 Y축으로 설정하여 각 값을 2차원 평면 위 점으로 나타낼 수 있다.  
이렇게 그린 그래프를 **산점도**(**scatter plot**)라고 한다.

<br/>

#### 상관
산점도를 이용하여 두 양적 변수의 관계를 시각화하면 대략적으로 어떤 관계가 있는지 파악할 수 있다. 이를 통해, 양의 관계인지 음의 관계인지 또는 관계가 없는지를 판단한다. 이러한 변수 사이의 관계성을 **상관**(**correlation**)이라고 한다.  
단, **상관관계를 안다고 하더라도 그게 원인과 결과의 관계인 지는 알 수 없다.**

<br/>

#### 회귀
**회귀**(**regression**), **회귀분석**(**regression analysis**)은 $y=f(x)$와 같은 함수를 통해 변수 사이의 관계를 공식화 하는 것을 의미한다. 회귀에서는 $x$를 설명변수 또는 독립변수, $y$를 반응변수 또는 종속변수라고 부른다.

<br/>
<br/>

### 상관관계
#### 피어슨 상관계수
양적 변수 2개의 관계성이 어느 정도로 강한지를 수치로 나타낼 수 있다면, 이해에 도움이 되지 않을까? 가장 자주 사용하는 것이 **피어슨 상관계수**(**Pearson's correlation**, $r$)이다.  
표본크기 n인 2개의 양적 변수 데이터를 각각 $x_1, x_2,...,x_n$과 $y_1, y_2, ..., y_n$이라 할 때, 피어슨 상관계수 $r$은 아래와 같이 정의된다.

$$r = \frac{\frac{1}{n}\sum_{i=1}^{n}(x_{i}-\overline{x})(y_{i}-\overline{y})}{\sqrt{\frac{1}{n}\sum_{j=1}^{n}(x_{j}-\overline{x})^2}\sqrt{\frac{1}{n}\sum_{k=1}^{n}(y_{k}-\overline{y})^2}}$$

이때 $r$이 가질 수 있는 값의 범위는 $-1 \leq r \leq 1$이다. 분자는 공분산(covariance)이다. 분모는 $x_i$, $y_i$ 각각의 표준편차이다.  
$r$ 값이 양수일 때는 $x$가 커질수록 $y$도 함께 커지고(양의 상관관계, positive correlation), $r$ 값이 음수일 때는 $x$가 커지면 $y$는 작아지는(음의 상관관계, negative correlation) 관계를 가진다.  
$r$ 값이 1 또는 -1에 가까울수록 $x$와 $y$의 관계는 직선에 가깝게 표현할 수 있다. 1 또는 -1의 값을 가지면 완전한 직선 관계이다. 반대로 0에 가까워지면 $x$와 $y$의 관계는 점점 불분명해지며, 값이 0이면 완전히 상관이 없다고 본다.

상관관계의 정도에 따라 구분을 하는데, 이는 분야에 따라 다르므로 참고만 하자.
- $0.7 \lt \vert r \vert \le 1$ : 강한 상관관계
- $0.4 \lt \vert r \vert \le 0.7$ : 중간 정도의 상관관계
- $0.2 \lt \vert r \vert \le 0.4$ : 약한 상관관계
- $0.0 \lt \vert r \vert \le 0.2$ : 거의 상관이 없음

피어슨 상관계수 $r$은 두 변수의 관계의 정도를 정량화하여 나타내는 유용한 도구이나 주의점이 있다.
1. 피어슨 상관계수 $r$은 두 양적 변수의 "**선형**" 관계의 정도를 정량화한 것이다.  
2차 함수, 4차 함수 같은 **비선형 관계를 피어슨 상관계수 $r$로 적절하게 정량화 할 수는 없다!**
2. 피어슨 상관계수 $r$는 관계의 정도를 나타낼 때, **직선의 기울기 값**은 고려 대상이 아니다.  
3. $r$ 값이 같더라도 데이터의 분포가 다를 수 있다. 비선형 관계를 포함하여서!  
그렇기에 상관계수를 계산하기 전에 산점도를 그려서 데이터의 분포를 확인하라.
4. 피어슨 상관계수 $r$은 평균과 분산에 기반한 모수적인 방법이다. 그렇기에 $x$와 $y$의 분포가 정규분포라고 가정한다. 따라서 데이터가 정규분포의 형태를 가지지 않을 때(쌍봉형 분포, 이상치 존재 등) 적절하게 동작하지 않는다.  
그렇기에 상관계수 계산 전에 $x$축, $y축$ 데이터 각각에 대해 정규성을 검정한다. 샤피로-윌크 검정 등으로.

<br/>

#### 비모수 상관계수
$x$축, $y$축 데이터에 대해 정규성을 검정했더니 두 데이터 모두 없거나, 또는 하나의 데이터에 없을 수 있다. 이때 **스피어만 순위상관계수**(**Spearman's rank correlation coefficient**, $\rho$)를 사용한다. $\rho$ 또한, $r$처럼 -1에서 1까지의 값을 범위로 가진다.  
스피어만 순위상관계수 $\rho$는 데이터의 값을 $x$축, $y$축 각각에서 크기 순으로 나열한 후, 피어슨 상관계수의 공식을 이용한다. 이 방식은 이상치를 포함하여도 결과에 거의 영향을 주지 않는다.

**켄달 순위상관계수**(**Kendall rank correlation coefficient**, $\tau$)도 있다. 스피어만 순위상관계수와 유사한 역할을 한다. 사용 대상은 거의 비슷하지만, **표본크기 $n$이 매우 작을 때**(10 미만) 켄달 순위상관계수가 유의성 검정 관점에서 더 좋다고 한다.

상관관계를 계산할 때, 두 변수가 처음부터 종속 관계일 때는 주의가 필요하다. 이를테면, 수학 점수 변수 $X$, 과학 점수 변수 $Y$가 있다고 할 때, 수학 점수와 과학 점수를 합한 $W$란 변수를 만들었다고 하자. $x$축에 수학 점수 $X$를 놓고, $y$축에 새로운 변수 $W$를 놓은 후 상관계수를 계산하면, $y$축에 $x$축의 값이 포함된다. 이런 경우, 실제로는 수학 점수와 과학 점수의 상관관계가 없다고 하더라도 관계성이 있다는 결과가 나타난다. 이 현상은 피어슨 상관계수 $r$, 스피어만 순위상관계수 $\rho$ 모두에서 발생한다.

<br/>

#### 상관계수와 가설
~~p.188 ~ p.191 상관계수와 가설검정 단락은... 상관계수만 보고서 p-value 확인하고 검정하는게 좀 말이 안 되지 않나...?~~

<br/>

#### 비선형 상관
보다 포괄적인 상관의 원리로서 정보량에 기반을 둔 지표가 제안이 되고 있다. [링크](https://www.science.org/doi/10.1126/science.1205438)  
이는 '$X$가 $Y$에 관해, 또는 $Y$가 $X$에 관해 어느 정도의 정보를 포함하는지'의 관점에서 관계성의 정도를 정량화 하는 것이다. $X$와 $Y$가 관계성이 있다는 것은 '$X$를 알면 $Y$도 알 수 있다' 또는 '$Y$를 알면 $X$도 알 수 있다'를 의미한다. 이러한 정보 기반의 생각에서는 비선형 관계도 포함하는 것이 일반적이다.

<br/>
<br/>

### 선형회귀
회귀란, 설명변수 $x$와 반응변수 $y$ 사이에 $y=f(x)$와 같은 함수를 적용시키는 것이다. 이러한 **회귀식**을 얻을 수 있다면, 설명변수와 반응변수 사이의 관계성을 알 수 있다.  

$y = a +bx$라는 단순회귀식을 보자. $a$, $b$는 실수 파라미터이다. 이 단순회귀식은 1차 함수이므로 $a$는 절편, $b$는 기울기라고도 할 수 있다. $a$, $b$에 구체적인 값을 넣으면 하나의 회귀직선을 그릴 수 있다. 이처럼 회귀식 $f(x)$의 형태를 결정하는 파라미터 $a$, $b$를 **회귀계수**(**regression coefficient**)라고 한다.  
회귀의 적합도를 평가하고, 적절한 회귀계수 값을 예측하는 것이 회귀분석의 큰 흐름이다.

$$y = a + bx +  \varepsilon$$

실제 현상에서 발생되는 관측치를 위의 식처럼 수학적으로 설명하는 것을 **모형**(**model**)이라고 한다. 이 모형은 회귀식을 설명하는 모형이므로, **회귀모형**이라 부를 수 있다.  
> **모형**이란, 현상의 중요한 부분에 주목하여 이를 단순화하고 수학적으로 다룰 수 있도록 만든 것.

회귀분석을 실행할 때 중요한 점은 다음과 같다.
- 어떤 회귀식을 적용할 것인가?
- 데이터에 회귀식을 어떻게 적용할 것인가?
- 회귀모형에 대한 평가를 어떻게 할 것인가?

가장 단순한 회귀모형 $y = a + bx + \varepsilon$을 살펴보자. $a$, $b$에 적절한 값을 넣어 실제 현상을 잘 설명할 수 있도록 만들어야 한다. 그렇다면 적절한 $a$, $b$는 어떻게 정할 수 있을까? 모형의 적합도를 판단하는 어떠한 기준이 필요하다. **모형의 식과 데이터의 차이가 최대한 작을수록** 좋은 모형이라고 할 수 있지 않을까?

데이터 $x_1, x_2, ..., x_n$, $y_1, y_2, ..., y_n$가 있다고 가정하자. 이 때 $x_i$를 모형의 식에 넣어서 구한 값을 $\hat{y}$로 나타낼 수 있고, $\hat{y}_i = a + bx_i$가 성립한다. 이후 $\hat{y}_i$와 실제 데이터 $y_i$의 차이($\hat{y}_i - y_i$)를 보는데, 이를 **잔차**라고 한다. 이 잔차들을 제곱하고 모두 합하면 $E$가 되는데, 즉 $E$는 "모형의 식과 데이터의 차이의 총합"이다.  
이 $E$가 클수록 모형의 식에 넣어 구한 값($\hat{y}_i$)과 실제 데이터($y_i$)가 크게 다르다는 것이고 이는 모형이 실제 현상에 대해 설명을 못한다고 할 수 있다. 반대로 $E$가 작을수록 모형의 식에 넣어 구한 값과 실제 데이터가 비슷하다는 것이고 이는 모형이 실제 현상을 잘 설명한다고 할 수 있다.
$E$는 회귀계수 $a$, $b$가 어떤 값을 가지느냐에 따라 달라진다. 근본적으로 $E$ 자체를 줄이기 위해서 **최소제곱법**(**least squares**)를 사용한다.

<br/>

#### 결정계수
회귀모형의 식에 대한 평가 지표로 **결정계수**(**coefficient of determination, R-squared**)를 사용한다.

$$R^2 = 1 - \frac{ \sum_{i=1}^{n}(y_i - f(x_i))^2 }{ \sum_{j=1}^{n}(y_j - \overline{y})^2 }$$

분자는 '회귀모형의 식과 실제 데이터의 차이'(=$\hat{y} - y$)를 제곱한 것의 총합을 나타내며, 분모는 반응변수($y$) 전체의 분산을 나타낸다. 이는 반응변수 전체 분산에 대하여 **설명되지 않고 남아있는 차이가 비율로 어느 정도나 되는지**를 의미한다. 이 값을 1에서 뺌으로써 최종적으로, 결정계수 $R^2$는 **회귀모형의 식에 의해 설명된 비율**을 의미한다. $R^2$가 1에 가까울수록 회귀모형이 실제 현상을 잘 반영하는 것을 의미하고, 0에 가까울수록 실제 현상과 부합하지 않음을 의미한다.  
> 설명변수가 1개인 1차 함수의 선형회귀에서 최소제곱법을 이용할 때, 결정계수 $R^2$는 변수 $x$, $y$ 사이의 피어슨 상관계수 $r$을 제곱한 값과 같다.  
> ~~다른 경우에는...?~~

결정계수 $R^2$는 설명변수의 수가 늘어날수록 커지는 성질이 있다. 그래서 무의미한 설명변수를 모형에 넣었을 때, 모형의 설명력이 올라간 것으로 보일 수 있다. 이를 방지하기 위해 설명변수의 수 $k$에 따라 조정한 **조정 결정계수**(**Adjusted R-squared**, $R_{adj}^{2}$)를 사용하기도 한다.

$$R_{adj}^{2} = 1 - \frac{ \frac{1}{n-k-1} \sum_{i=1}^{n}(y_i - f(x_i))^2 }{ \frac{1}{n-1} \sum_{j=1}^{n}(y_j - \overline{y})^2 }$$

설명변수의 수 $k$에 따라 값이 달라진다. 설명변수가 적을수록 결정계수 $R^2$과 거의 비슷한 값이 된다. $R^2$이건, $R_{adj}^{2}$이건 적절하지 않은 모형으로 계산하면 값이 음수가 될 수도 있다.

<br/>

#### 오차의 등분산성과 정규성
~~작성 예정~~

<br/>

#### 설명변수와 반응변수
분석을 하기 전에 무엇을 설명변수로 삼고, 무엇을 반응변수로 둘 것인지 목적에 맞게 생각하라.

1. 하나의 변수로 또다른 하나의 변수를 설명하고자 할 때.
2. 인과효과를 알고자 할 때.
3. 데이터를 예측하고 싶을 때.  
예측에 특화된 모형은 반드시 해석 가능한 것이 아니다. ~~머신러닝...~~