---
title: "[도서 정리]통계 101 x 데이터 분석"
excerpt: "9장. 가설검정의 주의점"
classes: wide

categories:
  - Notes
---
# 통계 101 x 데이터 분석
## 9장. 가설검정의 주의점

가설검정을 비롯한 통계 방법론이 정말 올바르게 쓰이고 있을까?

<br/>

### 재현성
#### 가설검정, 이해는 어렵지만 시행은 간단
통계 소프트웨어나 R, Python을 이용하여서 대충 모델 뚝딱 돌리니 '$p<0.05$가 나오더라, 그러니까 이거 유의미한 거 아님?' 암암리에 이러한 사고방식을 가진 연구자가 많아졌다. 그래서 **재현성 위기**가 발생했다나.

<br/>

#### 재현성 위기
##### $p$-값을 둘러싼 논쟁
관례적으로 사용되던 $p$-값에 대한 논쟁은 계속 심화되고 있다. $p$-값을 사용하지 말자는 주장도 있고, 유의수준 $\alpha=0.05$를 수정해야 한다는 주장도 있다.

##### 과학에서의 재현성
**재현성**(**Reproducibility, Replication**)이란, **조건이 동일하다면, 언제 어디서 실험하더라도 같은 결과를 얻을 수 있어야 한다**는 것을 의미한다. 문제는 최근의 논문들에 대해 다른 연구자가 동일한 조건, 방법으로 실험을 해도 논문과 같은 결과를 얻지 못하는 경우가 늘었다는 점이다. 재현이 안 된다는 것은, 논문의 주장이 사실은 잘못되었을 가능성을 시사하므로 중대한 문제라고 할 수 있다.

#### 재현 불가능의 원인
원인이야 다양하겠지만, 조건을 동일하게 하는 것이 어려운 것도 큰 이유 중 하나 아닐까. 특히, 사회학, 심리학 등 사람을 대상으로 하는 학문에서 재현을 하기 위해 실험 조건을 동일하게 맞추는 것은 불가능에 가까울 것이다. 더불어, 가설검정을 할 때 잘못된 관행도 한몫 할 것이다. 가설검정 사용 방법에 따라 $p$-값이 0.05보다 작아지게 조작이 가능하다. 이를 **$p$-해킹**(**$p$-hacking**)이라고 한다.

가설검정에서는 1종 오류(False Positive)가 발생할 확률을 유의수준 $\alpha$로 설정하고, 이를 통제한다는 것이 중요하다. $p$-해킹에 의해 1종 오류가 일어날 확률이 유의수준 $\alpha$보다 커지는 것은 심각한 문제이다. ~~그러니까, 준조작 행위로 실험 결과상 차이가 없음에도 차이가 있다고 구라를 칠 수 있어서 문제인거다.~~

<br/>
<br/>

### 가설검정의 문제점
#### $p$-값
$p$-값이란, **$H0$가 참이라고 가정하고, 실제 관측하여 수집한 데이터를 얻을 확률 혹은 수집한 것 이상으로 극단적인 데이터를 얻을 확률**이다. $p$-값이 작을수록 $H0$와 실제 수집한 데이터 사이에 간극이 크다고 보는 것이고, 더 나아가 $p$-값이 우리가 설정한 유의수준 $\alpha$보다 작을 때 $H0$를 기각하기까지 한다. 이런 과정에서 **실제로 차이가 없음에도 차이가 있다고 판단**할 확률(=1종 오류 발생 확률)을 $\alpha$ 아래로 유지한다.

관례랄지... 유의수준 $\alpha$를 0.05로 설정해놓는 경우가 많아, $H0$가 참이라 하더라도 20번 중 한 번은 $p < \alpha$가 나타나기도 한다. ~~이게 무슨 말이냐면, 보통 $H0$는 우리가 반박하고 싶은 주장이라 "참"이어서는 안 되고, 기각해야 할 대상이다. 이 $H0$를 기각할 마땅한 근거가 없는데, 20번 중 한 번 꼴로 기각을 해버린다는 거다.~~

##### 대체 $\alpha = 0.05$로 설정하는가?
~~과학적인 근거, 그런거 없다. 그냥 로널드 피셔 영감님이 썼으니까 따라 쓰는거다...~~  
문제는, 유의수준 $\alpha$를 0.05로 설정하고 '통계적으로 유의미하게 나왔음!'이라고 주장을 해도, 사실 $H0$를 기각하지 못했을 비율이 생각보다 높다는 거다. '그럼 $\alpha$를 낮추면 되는거 아냐?'라는 생각이 들 수 있는데, 유의수준 $\alpha$를 낮추면 2종 오류가 발생할 확률인 $\beta$가 커져버린다. 아무튼 그래서, 최근에는 유의수준 $\alpha$를 0.005로 더 낮춰서 사용하자고도 한다나.

<br/>

#### 피셔류 검정과 네이만-피어슨류 검정
**피셔류 검정**은 $H0$가 참이라 가정하고, 실제 관측하여 수집한 데이터 또는 그보다 더 극단적인 데이터를 얻을 확률을 계산한다(=$p$-값). 그 후, $H0$와 실제 관측하여 수집한 데이터의 차이 정도를 평가한다. 이 때의 검정 방식에서는 가설 기각/채택의 개념은 없고, $p$-값의 크기에 따라 증거의 강도만 본다.

**네이만-피어슨류 검정**은 $p$-값이 유의수준 $\alpha$ 미만인가 이상인가에 주목하여 가설을 기각하거나 채택하는 결론을 내린다. 이 양반들은 $p$-값이 0.04이건 0.000001이건 설정한 유의수준보다 작으면 통계적으로 유의미하다고 봤다. 또한 $\alpha$, $\beta$를 **먼저** 설정하고서 그에 따라 필요한 표본크기 $n$을 결정해야 했다. 왜냐하면, 표본크기 $n$ 값이 크다면, 아주 미세한 차이일지라도 $H0$를 기각할 수 있기 때문이라나. ~~문제는 표본크기가 이미 정해져 있을 때도 있다는 거다~~

현대 통계학에서의 가설검정은 $p$-값이 0.05 미만인지 이상인지보다, $p$-값 자체를 표기하거나 0.05, 0.01, 0.001 등의 단계에 따라 * 기호를 붙인다.

##### 표본크기 정하기

